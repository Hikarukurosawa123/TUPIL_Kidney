{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import re\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "from torchvision.transforms import functional as F\n",
        "from torchvision.transforms import InterpolationMode\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.io import loadmat\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Torchvision version: {models.__version__ if hasattr(models, '__version__') else 'N/A'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Environment detection and path configuration\n",
        "\n",
        "def is_google_colab() -> bool:\n",
        "    try:\n",
        "        import google.colab  # type: ignore  # noqa: F401\n",
        "\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def is_google_drive_mounted() -> bool:\n",
        "    return os.path.exists(\"/content/drive/MyDrive\")\n",
        "\n",
        "\n",
        "def configure_paths() -> Tuple[str, str, str, str, str]:\n",
        "    if is_google_colab() and is_google_drive_mounted():\n",
        "        base = \"/content/drive/MyDrive/Hikaru_Colab_Workspace/TUPIL_Kidney\"\n",
        "        print(\"Running on Google Colab with Google Drive mounted\")\n",
        "    elif is_google_colab():\n",
        "        base = \"/content\"\n",
        "        print(\"Running on Google Colab without Google Drive mounted\")\n",
        "    else:\n",
        "        base = \"/Users/hikaru/Desktop/TUPIL/Code/TUPIL_Kidney\"\n",
        "        print(\"Running locally\")\n",
        "\n",
        "    csv_file = os.path.join(base, \"csv\", \"patient_eGFR_at_pocus_2025_Jul_polynomial_estimation.csv\")\n",
        "    qus_dir = os.path.join(base, \"data\", \"QUS_resized\")\n",
        "    sample_id_file = os.path.join(base, \"data\", \"QUS_combined\", \"sample_id_combined.mat\")\n",
        "    b_mode_folder = os.path.join(base, \"data\", \"Bmode_resized\")\n",
        "    model_weights_path = os.path.join(base, \"data\", \"model_weights\", \"RadImageNet-ResNet50_notop.h5\")\n",
        "\n",
        "    return base, csv_file, qus_dir, sample_id_file, b_mode_folder, model_weights_path\n",
        "\n",
        "\n",
        "BASE_DIR, CSV_FILE, QUS_DATA_DIR, SAMPLE_ID_FILE, B_MODE_IMAGE_FOLDER, MODEL_WEIGHTS_PATH = configure_paths()\n",
        "IMAGE_FOLDERS = {\"B_mode\": B_MODE_IMAGE_FOLDER}\n",
        "\n",
        "print(f\"BASE_DIR: {BASE_DIR}\")\n",
        "print(f\"CSV file: {CSV_FILE}\")\n",
        "print(f\"QUS data directory: {QUS_DATA_DIR}\")\n",
        "print(f\"Sample ID file: {SAMPLE_ID_FILE}\")\n",
        "print(f\"B-mode folder: {B_MODE_IMAGE_FOLDER}\")\n",
        "print(f\"Model weights path (if needed): {MODEL_WEIGHTS_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ALL_QUS_TYPES = {\"ESD\", \"EAC\", \"SI\", \"SS\", \"MBF\"}\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Patient:\n",
        "    patient_id: int\n",
        "    egfr_label: int\n",
        "    egfr_value: float\n",
        "    b_mode_paths: List[str]\n",
        "    qus_case_indices: Dict[str, List[int]]\n",
        "\n",
        "    def count(self, input_type: str) -> int:\n",
        "        if input_type == \"B_mode\":\n",
        "            return len(self.b_mode_paths)\n",
        "        return len(self.qus_case_indices.get(input_type, []))\n",
        "\n",
        "    def min_samples(self, input_types: List[str]) -> int:\n",
        "        counts = [self.count(input_type) for input_type in input_types]\n",
        "        return min(counts) if counts else 0\n",
        "\n",
        "\n",
        "def extract_patient_id_from_sample(sample_id: str) -> int:\n",
        "    match = re.search(r\"P(\\d+)\", sample_id)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    raise ValueError(f\"Unable to parse patient ID from sample ID: {sample_id}\")\n",
        "\n",
        "\n",
        "def extract_matlab_string(cell_item) -> str:\n",
        "    if isinstance(cell_item, np.ndarray):\n",
        "        if cell_item.size == 0:\n",
        "            return \"\"\n",
        "        if cell_item.dtype.kind in {\"U\", \"S\"}:\n",
        "            return str(cell_item.flat[0])\n",
        "        if cell_item.dtype == object:\n",
        "            return extract_matlab_string(cell_item.flat[0])\n",
        "        return str(cell_item.flat[0])\n",
        "    return str(cell_item)\n",
        "\n",
        "\n",
        "def load_sample_ids(sample_id_file: str) -> List[str]:\n",
        "    if not os.path.exists(sample_id_file):\n",
        "        raise FileNotFoundError(f\"Sample ID file not found: {sample_id_file}\")\n",
        "\n",
        "    mat_data = loadmat(sample_id_file, struct_as_record=False, squeeze_me=True)\n",
        "    keys = [key for key in mat_data.keys() if not key.startswith(\"__\")]\n",
        "    if not keys:\n",
        "        raise ValueError(\"No data found in sample ID file\")\n",
        "\n",
        "    sample_var = mat_data[keys[0]]\n",
        "    sample_ids: List[str] = []\n",
        "\n",
        "    if isinstance(sample_var, np.ndarray):\n",
        "        for item in np.ravel(sample_var):\n",
        "            sample_ids.append(extract_matlab_string(item))\n",
        "    elif isinstance(sample_var, (list, tuple)):\n",
        "        sample_ids = [extract_matlab_string(x) for x in sample_var]\n",
        "    else:\n",
        "        sample_ids = [extract_matlab_string(sample_var)]\n",
        "\n",
        "    return [sid.strip() for sid in sample_ids if sid]\n",
        "\n",
        "\n",
        "def load_qus_arrays(qus_dir: str, qus_types: List[str]) -> Dict[str, np.ndarray]:\n",
        "    qus_arrays: Dict[str, np.ndarray] = {}\n",
        "    for qus_name in qus_types:\n",
        "        npy_path = os.path.join(qus_dir, f\"{qus_name}.npy\")\n",
        "        if not os.path.exists(npy_path):\n",
        "            raise FileNotFoundError(f\"QUS file not found: {npy_path}\")\n",
        "        qus_arrays[qus_name] = np.load(npy_path)\n",
        "        print(f\"Loaded {qus_name} with shape {qus_arrays[qus_name].shape}\")\n",
        "    return qus_arrays\n",
        "\n",
        "\n",
        "def load_b_mode_image_map(image_folder: str) -> Dict[int, List[str]]:\n",
        "    image_map: Dict[int, List[str]] = defaultdict(list)\n",
        "    if not os.path.exists(image_folder):\n",
        "        print(f\"Warning: B-mode folder not found: {image_folder}\")\n",
        "        return image_map\n",
        "\n",
        "    for filename in sorted(os.listdir(image_folder)):\n",
        "        if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "            continue\n",
        "        parts = filename.split(\"_\")\n",
        "        if len(parts) < 2 or parts[0] != \"Patient\":\n",
        "            continue\n",
        "        try:\n",
        "            patient_id = int(parts[1])\n",
        "        except ValueError:\n",
        "            continue\n",
        "        image_map[patient_id].append(os.path.join(image_folder, filename))\n",
        "    return image_map\n",
        "\n",
        "\n",
        "def build_patients(\n",
        "    input_types: List[str],\n",
        "    image_folders: Dict[str, str],\n",
        "    csv_file: str,\n",
        "    qus_arrays: Dict[str, np.ndarray],\n",
        "    sample_ids: List[str],\n",
        ") -> List[Patient]:\n",
        "    egfr_df = pd.read_csv(csv_file)\n",
        "    egfr_df.rename(columns={\"Patient ID\": \"patient_id\", \"eGFR (abs/closest)\": \"eGFR\"}, inplace=True)\n",
        "    egfr_df[\"patient_id\"] = egfr_df[\"patient_id\"].astype(int)\n",
        "    egfr_df.set_index(\"patient_id\", inplace=True)\n",
        "\n",
        "    selected_qus_types = [input_type for input_type in input_types if input_type in ALL_QUS_TYPES]\n",
        "    use_b_mode = \"B_mode\" in input_types\n",
        "\n",
        "    # Map patient -> qus case indices\n",
        "    qus_case_map: Dict[int, Dict[str, List[int]]] = defaultdict(lambda: {qus_type: [] for qus_type in selected_qus_types})\n",
        "    if selected_qus_types:\n",
        "        if not sample_ids:\n",
        "            raise ValueError(\"Sample IDs are required when QUS inputs are selected\")\n",
        "        num_cases_expected = None\n",
        "        for qus_type in selected_qus_types:\n",
        "            num_cases = qus_arrays[qus_type].shape[2]\n",
        "            if num_cases_expected is None:\n",
        "                num_cases_expected = num_cases\n",
        "            elif num_cases_expected != num_cases:\n",
        "                raise ValueError(\"All QUS arrays must have the same number of cases\")\n",
        "        if num_cases_expected and len(sample_ids) != num_cases_expected:\n",
        "            raise ValueError(\"Number of sample IDs does not match QUS cases\")\n",
        "\n",
        "        for case_idx, sample_id in enumerate(sample_ids):\n",
        "            try:\n",
        "                patient_id = extract_patient_id_from_sample(sample_id)\n",
        "            except ValueError:\n",
        "                continue\n",
        "            if patient_id not in egfr_df.index:\n",
        "                continue\n",
        "            for qus_type in selected_qus_types:\n",
        "                qus_case_map[patient_id][qus_type].append(case_idx)\n",
        "\n",
        "    # Map patient -> B-mode image paths\n",
        "    b_mode_map: Dict[int, List[str]] = defaultdict(list)\n",
        "    if use_b_mode:\n",
        "        b_mode_map = load_b_mode_image_map(image_folders.get(\"B_mode\", \"\"))\n",
        "\n",
        "    patients: List[Patient] = []\n",
        "    for patient_id in egfr_df.index:\n",
        "        egfr_value = float(egfr_df.loc[patient_id, \"eGFR\"])\n",
        "        egfr_label = 1 if egfr_value >= 60 else 0\n",
        "\n",
        "        patient_qus_indices = qus_case_map.get(patient_id, {qus_type: [] for qus_type in selected_qus_types})\n",
        "        patient_b_mode_paths = b_mode_map.get(patient_id, [])\n",
        "\n",
        "        has_all_inputs = True\n",
        "        for input_type in input_types:\n",
        "            if input_type == \"B_mode\":\n",
        "                if not patient_b_mode_paths:\n",
        "                    has_all_inputs = False\n",
        "                    break\n",
        "            else:\n",
        "                if not patient_qus_indices.get(input_type):\n",
        "                    has_all_inputs = False\n",
        "                    break\n",
        "        if not has_all_inputs:\n",
        "            continue\n",
        "\n",
        "        patients.append(\n",
        "            Patient(\n",
        "                patient_id=patient_id,\n",
        "                egfr_label=egfr_label,\n",
        "                egfr_value=egfr_value,\n",
        "                b_mode_paths=patient_b_mode_paths,\n",
        "                qus_case_indices=patient_qus_indices,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return patients\n",
        "\n",
        "\n",
        "def summarize_patients(patients: List[Patient], input_types: List[str]) -> None:\n",
        "    print(f\"Number of patients: {len(patients)}\")\n",
        "    for input_type in input_types:\n",
        "        counts = [patient.count(input_type) for patient in patients]\n",
        "        if not counts:\n",
        "            continue\n",
        "        print(\n",
        "            f\"{input_type}: total={sum(counts)}, min={min(counts)}, max={max(counts)}, avg={np.mean(counts):.2f}\"\n",
        "        )\n",
        "\n",
        "\n",
        "GLOBAL_QUS_ARRAYS: Dict[str, np.ndarray] = {}\n",
        "GLOBAL_SAMPLE_IDS: List[str] = []\n",
        "GLOBAL_TRAIN_SCALERS: Dict[str, Tuple[float, float]] = {}\n",
        "\n",
        "\n",
        "def load_patients(\n",
        "    input_types: List[str],\n",
        "    image_folders: Dict[str, str],\n",
        "    csv_file: str,\n",
        "    qus_arrays: Dict[str, np.ndarray] | None = None,\n",
        "    sample_ids: List[str] | None = None,\n",
        ") -> List[Patient]:\n",
        "    resolved_qus_arrays = qus_arrays if qus_arrays is not None else GLOBAL_QUS_ARRAYS\n",
        "    resolved_sample_ids = sample_ids if sample_ids is not None else GLOBAL_SAMPLE_IDS\n",
        "    return build_patients(input_types, image_folders, csv_file, resolved_qus_arrays, resolved_sample_ids)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Legacy TensorFlow-style patient helpers (not used)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Input configuration and experiment hyperparameters\n",
        "\n",
        "# QUS Options: 'ESD', 'EAC', 'SI', 'SS', 'MBF'\n",
        "# Image Option: 'B_mode'\n",
        "# Specify any combination you would like to experiment with\n",
        "INPUT_TYPES = ['ESD', 'EAC', 'SI', 'SS', 'MBF', 'B_mode']\n",
        "# Examples:\n",
        "# INPUT_TYPES = ['ESD']\n",
        "# INPUT_TYPES = ['ESD', 'EAC', 'B_mode']\n",
        "# INPUT_TYPES = ['B_mode']\n",
        "\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 100\n",
        "EARLY_STOPPING_PATIENCE = 20\n",
        "LEARNING_RATE = 1e-4\n",
        "STEP_LR_EVERY = 15\n",
        "STEP_LR_GAMMA = 0.5\n",
        "N_RUNS = 5\n",
        "BASE_SEED = 42\n",
        "\n",
        "QUS_TYPES = [t for t in INPUT_TYPES if t in ALL_QUS_TYPES]\n",
        "IMAGE_TYPES = [t for t in INPUT_TYPES if t == 'B_mode']\n",
        "\n",
        "print(f\"Selected input types: {INPUT_TYPES}\")\n",
        "print(f\"QUS types: {QUS_TYPES}\")\n",
        "print(f\"Image types: {IMAGE_TYPES}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (Deprecated intermediate definition of FlexiblePatientDataset removed in favor of the final PyTorch implementation below.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare modality resources for downstream loading\n",
        "\n",
        "SELECTED_QUS_TYPES = [input_type for input_type in INPUT_TYPES if input_type in ALL_QUS_TYPES]\n",
        "USE_B_MODE = \"B_mode\" in INPUT_TYPES\n",
        "GLOBAL_TRAIN_SCALERS = {}\n",
        "\n",
        "if SELECTED_QUS_TYPES:\n",
        "    GLOBAL_SAMPLE_IDS = load_sample_ids(SAMPLE_ID_FILE)\n",
        "    print(f\"Loaded {len(GLOBAL_SAMPLE_IDS)} sample IDs\")\n",
        "    GLOBAL_QUS_ARRAYS = load_qus_arrays(QUS_DATA_DIR, SELECTED_QUS_TYPES)\n",
        "else:\n",
        "    GLOBAL_SAMPLE_IDS = []\n",
        "    GLOBAL_QUS_ARRAYS = {}\n",
        "    print(\"No QUS inputs selected; proceeding with image-only data.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Legacy TensorFlow-style dataset placeholder (not used)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PyTorch dataset for flexible multimodal inputs (overrides earlier definition)\n",
        "\n",
        "class FlexiblePatientDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        patients: List[Patient],\n",
        "        input_types: List[str],\n",
        "        qus_arrays: Dict[str, np.ndarray] | None = None,\n",
        "        scalers: Dict[str, Tuple[float, float]] | None = None,\n",
        "        image_size: int = 224,\n",
        "        augment: bool = False,\n",
        "    ) -> None:\n",
        "        resolved_qus_arrays = qus_arrays if qus_arrays is not None else GLOBAL_QUS_ARRAYS\n",
        "        self.patients = patients\n",
        "        self.input_types = input_types\n",
        "        self.image_size = image_size\n",
        "        self.augment = augment\n",
        "        self.qus_arrays = resolved_qus_arrays\n",
        "        self.selected_qus_types = [input_type for input_type in input_types if input_type in ALL_QUS_TYPES]\n",
        "        self.use_b_mode = \"B_mode\" in input_types\n",
        "\n",
        "        self._records: List[Tuple[Patient, int]] = []\n",
        "        for patient in patients:\n",
        "            available = patient.min_samples(input_types)\n",
        "            for sample_idx in range(available):\n",
        "                self._records.append((patient, sample_idx))\n",
        "\n",
        "        self.samples = [(patient, patient.egfr_label, patient.patient_id) for patient, _ in self._records]\n",
        "        self.labels = [patient.egfr_label for patient, _ in self._records]\n",
        "        self.base_mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "        self.base_std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "\n",
        "        global GLOBAL_TRAIN_SCALERS\n",
        "        if scalers is not None:\n",
        "            self.scalers = scalers\n",
        "        else:\n",
        "            if GLOBAL_TRAIN_SCALERS and not augment:\n",
        "                self.scalers = GLOBAL_TRAIN_SCALERS\n",
        "            else:\n",
        "                if augment:\n",
        "                    GLOBAL_TRAIN_SCALERS = {}\n",
        "                self.scalers = self._compute_qus_scalers()\n",
        "                if self.selected_qus_types and augment:\n",
        "                    GLOBAL_TRAIN_SCALERS = self.scalers\n",
        "\n",
        "    def _compute_qus_scalers(self) -> Dict[str, Tuple[float, float]]:\n",
        "        scalers: Dict[str, Tuple[float, float]] = {}\n",
        "        for qus_type in self.selected_qus_types:\n",
        "            min_val = float(\"inf\")\n",
        "            max_val = float(\"-inf\")\n",
        "            for patient, sample_idx in self._records:\n",
        "                case_idx = patient.qus_case_indices[qus_type][sample_idx]\n",
        "                qus_map = np.nan_to_num(self.qus_arrays[qus_type][:, :, case_idx], nan=0.0)\n",
        "                local_min = float(np.min(qus_map))\n",
        "                local_max = float(np.max(qus_map))\n",
        "                if local_min < min_val:\n",
        "                    min_val = local_min\n",
        "                if local_max > max_val:\n",
        "                    max_val = local_max\n",
        "            if min_val == float(\"inf\") or max_val == float(\"-inf\"):\n",
        "                min_val, max_val = 0.0, 1.0\n",
        "            if max_val - min_val < 1e-6:\n",
        "                max_val = min_val + 1e-6\n",
        "            scalers[qus_type] = (min_val, max_val)\n",
        "        return scalers\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._records)\n",
        "\n",
        "    def _load_b_mode_tensor(self, path: str) -> torch.Tensor:\n",
        "        image = Image.open(path).convert(\"RGB\")\n",
        "        if image.size != (self.image_size, self.image_size):\n",
        "            image = image.resize((self.image_size, self.image_size))\n",
        "        tensor = F.to_tensor(image)\n",
        "        return tensor\n",
        "\n",
        "    def _load_qus_tensor(self, qus_type: str, patient: Patient, sample_idx: int) -> torch.Tensor:\n",
        "        case_idx = patient.qus_case_indices[qus_type][sample_idx]\n",
        "        qus_map = np.nan_to_num(self.qus_arrays[qus_type][:, :, case_idx], nan=0.0)\n",
        "        tensor = torch.from_numpy(qus_map).float().unsqueeze(0)\n",
        "        if tensor.shape[1] != self.image_size or tensor.shape[2] != self.image_size:\n",
        "            tensor = torch.nn.functional.interpolate(\n",
        "                tensor.unsqueeze(0),\n",
        "                size=(self.image_size, self.image_size),\n",
        "                mode=\"bilinear\",\n",
        "                align_corners=False,\n",
        "            ).squeeze(0)\n",
        "        min_val, max_val = self.scalers.get(qus_type, (0.0, 1.0))\n",
        "        if max_val > min_val:\n",
        "            tensor = (tensor - min_val) / (max_val - min_val)\n",
        "        tensor = tensor.clamp(0.0, 1.0)\n",
        "        return tensor\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
        "        patient, sample_idx = self._records[index]\n",
        "\n",
        "        modality_tensors: Dict[str, torch.Tensor] = {}\n",
        "\n",
        "        if self.use_b_mode:\n",
        "            b_mode_path = patient.b_mode_paths[sample_idx]\n",
        "            modality_tensors[\"B_mode\"] = self._load_b_mode_tensor(b_mode_path)\n",
        "\n",
        "        for qus_type in self.selected_qus_types:\n",
        "            modality_tensors[qus_type] = self._load_qus_tensor(qus_type, patient, sample_idx)\n",
        "\n",
        "        if self.augment:\n",
        "            do_flip = random.random() < 0.5\n",
        "            angle_deg = random.uniform(-14.0, 14.0)\n",
        "            zoom = random.uniform(0.9, 1.1)\n",
        "            for key, tensor in modality_tensors.items():\n",
        "                if do_flip:\n",
        "                    tensor = torch.flip(tensor, dims=[2])\n",
        "                tensor = F.affine(\n",
        "                    tensor,\n",
        "                    angle=angle_deg,\n",
        "                    translate=(0, 0),\n",
        "                    scale=zoom,\n",
        "                    shear=0.0,\n",
        "                    interpolation=InterpolationMode.BILINEAR,\n",
        "                )\n",
        "                modality_tensors[key] = tensor\n",
        "\n",
        "        processed_channels: List[torch.Tensor] = []\n",
        "        for input_type in self.input_types:\n",
        "            tensor = modality_tensors[input_type]\n",
        "            if input_type == \"B_mode\":\n",
        "                tensor = (tensor - self.base_mean) / self.base_std\n",
        "            else:\n",
        "                tensor = tensor.clamp(0.0, 1.0).repeat(3, 1, 1)\n",
        "            processed_channels.append(tensor)\n",
        "\n",
        "        concatenated = torch.cat(processed_channels, dim=0)\n",
        "        label = torch.tensor(patient.egfr_label, dtype=torch.float32)\n",
        "        return concatenated, label, patient.patient_id\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model builder: ResNet18 with flexible input channels\n",
        "\n",
        "def build_resnet18(num_input_channels: int, device: torch.device) -> nn.Module:\n",
        "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "    if num_input_channels != 3:\n",
        "        old_conv = model.conv1\n",
        "        model.conv1 = nn.Conv2d(\n",
        "            num_input_channels,\n",
        "            old_conv.out_channels,\n",
        "            kernel_size=old_conv.kernel_size,\n",
        "            stride=old_conv.stride,\n",
        "            padding=old_conv.padding,\n",
        "            bias=old_conv.bias is not None,\n",
        "        )\n",
        "        nn.init.kaiming_normal_(model.conv1.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "        if old_conv.bias is not None:\n",
        "            nn.init.zeros_(model.conv1.bias)\n",
        "    model.fc = nn.Linear(model.fc.in_features, 1)\n",
        "    return model.to(device)\n",
        "\n",
        "\n",
        "def count_trainable_parameters(model: nn.Module) -> int:\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training utilities\n",
        "\n",
        "def set_seeds(seed: int) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def compute_pos_weight(labels: List[int]) -> float:\n",
        "    positives = sum(labels)\n",
        "    negatives = len(labels) - positives\n",
        "    if positives == 0:\n",
        "        return 1.0\n",
        "    return max(1.0, negatives / max(positives, 1))\n",
        "\n",
        "\n",
        "def train_one_epoch(\n",
        "    model: nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    criterion: nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    device: torch.device,\n",
        ") -> Tuple[float, float]:\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    all_labels: List[float] = []\n",
        "    all_probs: List[float] = []\n",
        "\n",
        "    for images, labels, _ in dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(images).squeeze(1)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "        all_probs.extend(probs.tolist())\n",
        "        all_labels.extend(labels.detach().cpu().numpy().tolist())\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = total_loss / len(dataloader.dataset)\n",
        "    epoch_auc = roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else float(\"nan\")\n",
        "    return epoch_loss, epoch_auc\n",
        "\n",
        "\n",
        "def evaluate(\n",
        "    model: nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    criterion: nn.Module,\n",
        "    device: torch.device,\n",
        ") -> Tuple[float, float, Dict[int, List[float]], Dict[int, int]]:\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_labels: List[float] = []\n",
        "    all_probs: List[float] = []\n",
        "    patient_probs: Dict[int, List[float]] = defaultdict(list)\n",
        "    patient_labels: Dict[int, int] = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels, patient_ids in dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            logits = model(images).squeeze(1)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "\n",
        "            labels_np = labels.cpu().numpy()\n",
        "            patient_ids_np = patient_ids.numpy()\n",
        "\n",
        "            all_probs.extend(probs.tolist())\n",
        "            all_labels.extend(labels_np.tolist())\n",
        "\n",
        "            for pid, prob, lab in zip(patient_ids_np, probs, labels_np):\n",
        "                patient_probs[int(pid)].append(float(prob))\n",
        "                patient_labels[int(pid)] = int(lab)\n",
        "\n",
        "    epoch_loss = total_loss / len(dataloader.dataset)\n",
        "    epoch_auc = roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else float(\"nan\")\n",
        "    return epoch_loss, epoch_auc, patient_probs, patient_labels\n",
        "\n",
        "\n",
        "def plot_roc_curves(\n",
        "    probs: List[float],\n",
        "    labels: List[int],\n",
        "    patient_probs: Dict[int, List[float]],\n",
        "    patient_labels: Dict[int, int],\n",
        "    title_suffix: str,\n",
        ") -> Tuple[float, float]:\n",
        "    if len(set(labels)) > 1:\n",
        "        fpr_img, tpr_img, _ = roc_curve(labels, probs)\n",
        "        auc_img = roc_auc_score(labels, probs)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr_img, tpr_img, label=f\"Image ROC (AUC={auc_img:.4f})\", color=\"tab:blue\")\n",
        "        plt.plot([0, 1], [0, 1], \"k--\", label=\"Random\")\n",
        "        plt.xlabel(\"False Positive Rate\")\n",
        "        plt.ylabel(\"True Positive Rate\")\n",
        "        plt.title(f\"Image-level ROC {title_suffix}\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        auc_img = float(\"nan\")\n",
        "\n",
        "    patient_mean_probs = [np.mean(patient_probs[pid]) for pid in patient_probs]\n",
        "    patient_true = [patient_labels[pid] for pid in patient_probs]\n",
        "\n",
        "    if len(set(patient_true)) > 1:\n",
        "        fpr_pat, tpr_pat, _ = roc_curve(patient_true, patient_mean_probs)\n",
        "        auc_pat = roc_auc_score(patient_true, patient_mean_probs)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr_pat, tpr_pat, label=f\"Patient ROC (AUC={auc_pat:.4f})\", color=\"tab:green\")\n",
        "        plt.plot([0, 1], [0, 1], \"k--\", label=\"Random\")\n",
        "        plt.xlabel(\"False Positive Rate\")\n",
        "        plt.ylabel(\"True Positive Rate\")\n",
        "        plt.title(f\"Patient-level ROC {title_suffix}\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        auc_pat = float(\"nan\")\n",
        "\n",
        "    return auc_img, auc_pat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and summarize patient data\n",
        "\n",
        "all_patients = load_patients(\n",
        "    INPUT_TYPES,\n",
        "    IMAGE_FOLDERS,\n",
        "    CSV_FILE,\n",
        "    qus_arrays=GLOBAL_QUS_ARRAYS,\n",
        "    sample_ids=GLOBAL_SAMPLE_IDS,\n",
        ")\n",
        "if not all_patients:\n",
        "    raise RuntimeError(\"No patients found with the specified input types.\")\n",
        "\n",
        "summarize_patients(all_patients, INPUT_TYPES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hold-out runs with training, validation, and testing\n",
        "\n",
        "results = []\n",
        "\n",
        "for run_idx in range(N_RUNS):\n",
        "    global GLOBAL_TRAIN_SCALERS\n",
        "    GLOBAL_TRAIN_SCALERS = {}\n",
        "\n",
        "    seed = BASE_SEED + run_idx\n",
        "    set_seeds(seed)\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Run {run_idx + 1}/{N_RUNS} (seed={seed})\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    train_val_patients, test_patients = train_test_split(all_patients, test_size=0.1, random_state=seed)\n",
        "    train_patients, val_patients = train_test_split(train_val_patients, test_size=0.2, random_state=seed)\n",
        "\n",
        "    print(f\"Train patients: {len(train_patients)}\")\n",
        "    print(f\"Validation patients: {len(val_patients)}\")\n",
        "    print(f\"Test patients: {len(test_patients)}\")\n",
        "\n",
        "    train_dataset = FlexiblePatientDataset(train_patients, INPUT_TYPES, image_size=IMAGE_SIZE, augment=True)\n",
        "    train_scalers = train_dataset.scalers\n",
        "    GLOBAL_TRAIN_SCALERS = train_scalers\n",
        "    val_dataset = FlexiblePatientDataset(val_patients, INPUT_TYPES, scalers=train_scalers, image_size=IMAGE_SIZE, augment=False)\n",
        "    test_dataset = FlexiblePatientDataset(test_patients, INPUT_TYPES, scalers=train_scalers, image_size=IMAGE_SIZE, augment=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "    model = build_resnet18(num_input_channels=3 * len(INPUT_TYPES), device=device)\n",
        "    print(f\"Trainable parameters: {count_trainable_parameters(model):,}\")\n",
        "\n",
        "    train_labels = train_dataset.labels\n",
        "    pos_weight_value = compute_pos_weight(train_labels)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight_value, device=device))\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_LR_EVERY, gamma=STEP_LR_GAMMA)\n",
        "\n",
        "    best_val_auc = -1.0\n",
        "    best_state = None\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_loss, train_auc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_auc, val_patient_probs, val_patient_labels = evaluate(model, val_loader, criterion, device)\n",
        "        scheduler.step()\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:3d} | Train Loss: {train_loss:.4f} AUC: {train_auc:.4f} | \"\n",
        "            f\"Val Loss: {val_loss:.4f} AUC: {val_auc:.4f}\"\n",
        "        )\n",
        "\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            best_state = {\n",
        "                \"model\": model.state_dict(),\n",
        "                \"optimizer\": optimizer.state_dict(),\n",
        "            }\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        if epochs_without_improvement >= EARLY_STOPPING_PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    if best_state is None:\n",
        "        raise RuntimeError(\"Training did not yield a valid model state.\")\n",
        "\n",
        "    model.load_state_dict(best_state[\"model\"])\n",
        "\n",
        "    val_loss, val_auc, val_patient_probs, val_patient_labels = evaluate(model, val_loader, criterion, device)\n",
        "    val_probs_flat = [prob for probs in val_patient_probs.values() for prob in probs]\n",
        "    val_labels_flat = [val_patient_labels[pid] for pid, probs in val_patient_probs.items() for _ in probs]\n",
        "    val_img_auc, val_patient_auc = plot_roc_curves(\n",
        "        val_probs_flat,\n",
        "        val_labels_flat,\n",
        "        val_patient_probs,\n",
        "        val_patient_labels,\n",
        "        title_suffix=f\"(Validation Run {run_idx + 1})\",\n",
        "    )\n",
        "\n",
        "    test_loss, test_auc, test_patient_probs, test_patient_labels = evaluate(model, test_loader, criterion, device)\n",
        "    test_probs_flat = [prob for probs in test_patient_probs.values() for prob in probs]\n",
        "    test_labels_flat = [test_patient_labels[pid] for pid, probs in test_patient_probs.items() for _ in probs]\n",
        "    test_img_auc, test_patient_auc = plot_roc_curves(\n",
        "        test_probs_flat,\n",
        "        test_labels_flat,\n",
        "        test_patient_probs,\n",
        "        test_patient_labels,\n",
        "        title_suffix=f\"(Test Run {run_idx + 1})\",\n",
        "    )\n",
        "\n",
        "    preds_binary = [1 if prob >= 0.5 else 0 for prob in test_probs_flat]\n",
        "    print(\"Test classification report (image-level):\")\n",
        "    print(classification_report(test_labels_flat, preds_binary, digits=4))\n",
        "\n",
        "    results.append(\n",
        "        {\n",
        "            \"val_auc\": val_auc,\n",
        "            \"test_auc\": test_auc,\n",
        "            \"val_img_auc\": val_img_auc,\n",
        "            \"val_patient_auc\": val_patient_auc,\n",
        "            \"test_img_auc\": test_img_auc,\n",
        "            \"test_patient_auc\": test_patient_auc,\n",
        "        }\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate results across runs\n",
        "\n",
        "if results:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"FINAL SUMMARY OVER MULTIPLE HOLD-OUT RUNS\")\n",
        "    print(\"=\" * 60)\n",
        "    val_aucs = [entry[\"val_auc\"] for entry in results]\n",
        "    test_aucs = [entry[\"test_auc\"] for entry in results]\n",
        "    print(f\"Validation AUCs: {[f'{auc:.4f}' for auc in val_aucs]}\")\n",
        "    print(f\"Test AUCs:       {[f'{auc:.4f}' for auc in test_aucs]}\")\n",
        "    print(f\"\\nAverage Validation AUC: {np.mean(val_aucs):.4f} ± {np.std(val_aucs):.4f}\")\n",
        "    print(f\"Average Test AUC:       {np.mean(test_aucs):.4f} ± {np.std(test_aucs):.4f}\")\n",
        "else:\n",
        "    print(\"No runs executed yet.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-validation testing (patient-level K-Fold)\n",
        "\n",
        "N_FOLDS = 5\n",
        "cv_results = []\n",
        "\n",
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=BASE_SEED)\n",
        "\n",
        "for fold_idx, (train_val_idx, test_idx) in enumerate(kf.split(all_patients)):\n",
        "    global GLOBAL_TRAIN_SCALERS\n",
        "    GLOBAL_TRAIN_SCALERS = {}\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Cross-validation fold {fold_idx + 1}/{N_FOLDS}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    test_patients = [all_patients[i] for i in test_idx]\n",
        "    train_val_patients = [all_patients[i] for i in train_val_idx]\n",
        "\n",
        "    rng = np.random.default_rng(BASE_SEED + fold_idx)\n",
        "    rng.shuffle(train_val_patients)\n",
        "    val_split = max(1, int(len(train_val_patients) * 0.2))\n",
        "    val_patients = train_val_patients[:val_split]\n",
        "    train_patients = train_val_patients[val_split:]\n",
        "\n",
        "    print(f\"Training patients: {len(train_patients)}\")\n",
        "    print(f\"Validation patients: {len(val_patients)}\")\n",
        "    print(f\"Test patients: {len(test_patients)}\")\n",
        "\n",
        "    train_dataset = FlexiblePatientDataset(train_patients, INPUT_TYPES, image_size=IMAGE_SIZE, augment=True)\n",
        "    train_scalers = train_dataset.scalers\n",
        "    GLOBAL_TRAIN_SCALERS = train_scalers\n",
        "    val_dataset = FlexiblePatientDataset(val_patients, INPUT_TYPES, scalers=train_scalers, image_size=IMAGE_SIZE, augment=False)\n",
        "    test_dataset = FlexiblePatientDataset(test_patients, INPUT_TYPES, scalers=train_scalers, image_size=IMAGE_SIZE, augment=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "    model = build_resnet18(num_input_channels=3 * len(INPUT_TYPES), device=device)\n",
        "    print(f\"Trainable parameters: {count_trainable_parameters(model):,}\")\n",
        "\n",
        "    train_labels = train_dataset.labels\n",
        "    pos_weight_value = compute_pos_weight(train_labels)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight_value, device=device))\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_LR_EVERY, gamma=STEP_LR_GAMMA)\n",
        "\n",
        "    best_val_auc = -1.0\n",
        "    best_state = None\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        train_loss, train_auc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_auc, val_patient_probs, val_patient_labels = evaluate(model, val_loader, criterion, device)\n",
        "        scheduler.step()\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:3d} | Train Loss: {train_loss:.4f} AUC: {train_auc:.4f} | \"\n",
        "            f\"Val Loss: {val_loss:.4f} AUC: {val_auc:.4f}\"\n",
        "        )\n",
        "\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            best_state = {\n",
        "                \"model\": model.state_dict(),\n",
        "                \"optimizer\": optimizer.state_dict(),\n",
        "            }\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        if epochs_without_improvement >= EARLY_STOPPING_PATIENCE:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    if best_state is None:\n",
        "        raise RuntimeError(\"Training did not yield a valid model state.\")\n",
        "\n",
        "    model.load_state_dict(best_state[\"model\"])\n",
        "\n",
        "    val_loss, val_auc, val_patient_probs, val_patient_labels = evaluate(model, val_loader, criterion, device)\n",
        "    val_probs_flat = [prob for probs in val_patient_probs.values() for prob in probs]\n",
        "    val_labels_flat = [val_patient_labels[pid] for pid, probs in val_patient_probs.items() for _ in probs]\n",
        "    val_img_auc, val_patient_auc = plot_roc_curves(\n",
        "        val_probs_flat,\n",
        "        val_labels_flat,\n",
        "        val_patient_probs,\n",
        "        val_patient_labels,\n",
        "        title_suffix=f\"(Validation Fold {fold_idx + 1})\",\n",
        "    )\n",
        "\n",
        "    test_loss, test_auc, test_patient_probs, test_patient_labels = evaluate(model, test_loader, criterion, device)\n",
        "    test_probs_flat = [prob for probs in test_patient_probs.values() for prob in probs]\n",
        "    test_labels_flat = [test_patient_labels[pid] for pid, probs in test_patient_probs.items() for _ in probs]\n",
        "    test_img_auc, test_patient_auc = plot_roc_curves(\n",
        "        test_probs_flat,\n",
        "        test_labels_flat,\n",
        "        test_patient_probs,\n",
        "        test_patient_labels,\n",
        "        title_suffix=f\"(Test Fold {fold_idx + 1})\",\n",
        "    )\n",
        "\n",
        "    preds_binary = [1 if prob >= 0.5 else 0 for prob in test_probs_flat]\n",
        "    print(\"Test classification report (image-level):\")\n",
        "    print(classification_report(test_labels_flat, preds_binary, digits=4))\n",
        "\n",
        "    cv_results.append(\n",
        "        {\n",
        "            \"val_auc\": val_auc,\n",
        "            \"test_auc\": test_auc,\n",
        "            \"val_img_auc\": val_img_auc,\n",
        "            \"val_patient_auc\": val_patient_auc,\n",
        "            \"test_img_auc\": test_img_auc,\n",
        "            \"test_patient_auc\": test_patient_auc,\n",
        "        }\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-validation summary\n",
        "\n",
        "if cv_results:\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"FINAL CROSS-VALIDATION SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    cv_val_aucs = [entry[\"val_auc\"] for entry in cv_results]\n",
        "    cv_test_aucs = [entry[\"test_auc\"] for entry in cv_results]\n",
        "    print(f\"Validation AUCs: {[f'{auc:.4f}' for auc in cv_val_aucs]}\")\n",
        "    print(f\"Test AUCs:       {[f'{auc:.4f}' for auc in cv_test_aucs]}\")\n",
        "    print(f\"\\nAverage Validation AUC: {np.mean(cv_val_aucs):.4f} ± {np.std(cv_val_aucs):.4f}\")\n",
        "    print(f\"Average Test AUC:       {np.mean(cv_test_aucs):.4f} ± {np.std(cv_test_aucs):.4f}\")\n",
        "else:\n",
        "    print(\"Cross-validation has not been run yet.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
